{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron - MNIST\n",
    "\n",
    "For those of you unfamiliar with Jupyter notebooks, this is a concise explanation.\n",
    "Each \"cell\" of the notebook (a rectangular area) contains either explanatory text (\"Markdown,\" like this cell) or Python/Keras commands (\"Code\"). By clicking on this cell, you select it (and the contours are highlighted). If you press \"__Run__\" in the menu, Jupyter processes the contents of this cell and moves on to the next. Scroll to the next cell, read the command and press __Run__ again. The result of the command (if any) will become visible. Just proceed through the notebook in this fashion, and return to previous cells, whenever necessary (either to re-read an explanation or command, or to change parameters). Please note that if you want to restart the entire notebook, you have to start at the top.\n",
    "\n",
    "Let's start with importing the required plugins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces the training of 10 perceptrons with KERAS, a publicly available deep-learning library. KERAS runs on top of Tensorflow and other deep-learning frameworks. Documentation on KERAS can be found at https://keras.io/.\n",
    "\n",
    "Briefly explained, a perceptron is a simple neural network that has $I$ inputs. All $I$ inputs are connected to a single output. The $I$ connection weights, are trained to ensure that the output is activated whenever the inputs contain certain patterns. In our example, we train 10 perceptrons simultaneously on the same input to recognize handwritten digits '0' to '9'. Each perceptron takes care of detecting one of the digits; their output should become activated whenever one of the digits '0' to '9' appears in the input. The 10 outputs of the perceptrons are normalized to sum to one, so that their indivisual values can be interpreted as probabilities. The output with the largest probability given a certain input is the classification of the input. \n",
    "\n",
    "![](images/Perceptron.png)\n",
    ">_Illustration of the 10 combined perceptrons._\n",
    "\n",
    "The perceptrons are trained on the well-known MNIST dataset of handwritten digits. Each instance is a 28 x 28 pixel grayscale image and there are 10 targets (labels), i.e., '0', '1', .... '9'. The 28 x 28 pixel values are flattened to yield 784 inputs. Hence, in our combined multilayer perceptron (MLP), the number of inputs $I$ is equal to 784.\n",
    "\n",
    "The MNIST dataset consists of 60,000 training instances and 10,000 test \n",
    "instances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KERAS provides the MNIST dataset as training instances, the associated training labels, the test instances and their associated testing labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print('MNIST imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLP is trained on the training instances by presenting them together with their labels to the network. Below, we examine the shape of the training instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 60000 images are represented in a 3-dimensional array. Let's visualise the first 8 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.subplot(241)\n",
    "plt.imshow(train_images[10].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(242)\n",
    "plt.imshow(train_images[1].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(243)\n",
    "plt.imshow(train_images[2].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(244)\n",
    "plt.imshow(train_images[3].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(245)\n",
    "plt.imshow(train_images[4].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(246)\n",
    "plt.imshow(train_images[5].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(247)\n",
    "plt.imshow(train_images[6].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(248)\n",
    "plt.imshow(train_images[7].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to the training labels. Their number should equal the number of images (60000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the unique labels? These should be '0' to '9'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the labels (more-or-less) balanced? Are there about as many instances of each class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_labels)\n",
    "\n",
    "plt.title(\"Label Histogram\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "fig = plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our workflow will be as follows: first we will present our neural network with the training data, `train_images` and `train_labels`. The network will then learn to associate images and labels. Finally, we will ask the network to produce predictions for `test_images`, and we will verify if these predictions match the labels from `test_labels`.\n",
    "\n",
    "Let's build our network. It consists of:\n",
    "\n",
    "- An input layer of $28 \\times 28$ elements (each pixel value is an input, and the image matrix is represented in a vector of length $I = 28^2$)\n",
    "\n",
    "- The output layer which has $10$ outputs, one for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(10, use_bias='true', activation='softmax', input_shape=(28 * 28,)))\n",
    "\n",
    "print('Layers added.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The core building block of neural networks is the \"layer\", a data-processing module which you can conceive as a \"filter\" for data. Some \n",
    "data comes in, and comes out in a more useful form. Precisely, layers extract _representations_ out of the data fed into them -- hopefully \n",
    "representations that are more meaningful for the problem at hand. Most of deep learning really consists of chaining together simple layers \n",
    "which will implement a form of progressive \"data distillation\". A deep learning model is like a sieve for data processing, made of a \n",
    "succession of increasingly refined data filters -- the \"layers\".\n",
    "\n",
    "Here our network consists of a single `Dense` layer,  also called a \"fully-connected\" neural layer. \n",
    "The output layer is a 10-way \"softmax\" layer, which means it will return an array of 10 probability scores (summing to 1). Each \n",
    "score will be the probability that the current digit image belongs to one of our 10 digit classes.\n",
    "\n",
    "To make our network ready for training, we need to pick three more things, as part of \"compilation\" step:\n",
    "\n",
    "* A loss function: the is how the network will be able to measure how good a job it is doing on its training data, and thus how it will be \n",
    "able to steer itself in the right direction.\n",
    "* An optimizer: this is the mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    "* Metrics to monitor during training and testing. Here we will only care about accuracy (the fraction of the images that were correctly \n",
    "classified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.optimizers.SGD(lr=0.01)\n",
    "\n",
    "network.compile(optimizer='sgd',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "print('Network compiled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in \n",
    "the `[0, 1]` interval. Previously, our training images for instance were stored in an array of shape `(60000, 28, 28)` of type `uint8` with \n",
    "values in the `[0, 255]` interval. We transform it into a `float32` array of shape `(60000, 28 * 28)` with values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "print('Data processed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to categorically encode the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "print('Labels encoded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train our network, which in Keras is done via a call to the `fit` method of the network: \n",
    "we \"fit\" the model to its training data. The number of epochs may be changed to study its effect on the final result.\n",
    "The \"batch_size\" specifies the number of input patterns (instances) per weight update. A smaller batch size is more precise, but takes longer. A larger batch size may not be very precise, but is much faster.\n",
    "\n",
    "__Bonus Question: Experiment with several batch sizes to determine how it affects the duration and accuracy of training. (If your computer is too slow, reduce the number of epochs for answering this question.)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network.fit(train_images, train_labels, epochs=20, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two quantities are being displayed during training: the \"loss\" of the network over the training data, and the accuracy of the network over \n",
    "the training data. The loss should be as small as possible (it is a measure of the error the network makes on classifying handwritten digits). The accuracy (\"acc\") is the percentage correctly classified digits for the __training__ data. Please note that this number should be sufficiently high, but does not reveal anything about prediction, but instead specifies the degree of replication. In order to know how well the trained perceptrons generalize, we have to determine their performance on the test set.\n",
    "\n",
    "Typically, the performance (accuracy) on the test set tends to be lower than the performance on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bonus Question: Why is this the case?__\n",
    "\n",
    "__Bonus Question: How depends the difference in performance on train and test set on the number of epochs for training?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting feature of a perceptron (and of other neural networks) trained on images, is that we can visualise the weights after training. Each output has 26 x 26 weights forming a vector of 784 elements. Reshaping the vector in the matrix form that corresponds to that of the input image, allows us to visually interpret the weight patterns for each of the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = network.layers[0].get_weights()[0]\n",
    "WW = W1.reshape(28,28,10)\n",
    "WW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(2,5,1)\n",
    "plt.imshow(WW[:,:,0], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 0')\n",
    "plt.subplot(2,5,2)\n",
    "plt.imshow(WW[:,:,1], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 1')\n",
    "plt.subplot(2,5,3)\n",
    "plt.imshow(WW[:,:,2], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 2')\n",
    "plt.subplot(2,5,4)\n",
    "plt.imshow(WW[:,:,3], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 3')\n",
    "plt.subplot(2,5,5)\n",
    "plt.imshow(WW[:,:,4], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 4')\n",
    "plt.subplot(2,5,6)\n",
    "plt.imshow(WW[:,:,5], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 5')\n",
    "plt.subplot(2,5,7)\n",
    "plt.imshow(WW[:,:,6], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 6')\n",
    "plt.subplot(2,5,8)\n",
    "plt.imshow(WW[:,:,7], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 7')\n",
    "plt.subplot(2,5,9)\n",
    "plt.imshow(WW[:,:,8], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 8')\n",
    "plt.subplot(2,5,10)\n",
    "plt.imshow(WW[:,:,9], cmap=plt.get_cmap('gray'))\n",
    "plt.title('output 9')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bonus Question: What do you observe when inspecting the 10 weight matrices? Can you explain why the weights show these patterns?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interactive Python Notebook is based on https://github.com/fchollet/deep-learning-with-python-notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
